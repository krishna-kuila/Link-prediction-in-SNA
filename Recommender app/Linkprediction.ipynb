{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04552fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Found 973 Ego Networks ---\n",
      "Processing Ego Network: 100318079...\n",
      "Processing Ego Network: 10146102...\n",
      "Processing Ego Network: 101859065...\n",
      "Processing Ego Network: 101903164...\n",
      "Processing Ego Network: 102765423...\n",
      "Processing Ego Network: 102903198...\n",
      "Processing Ego Network: 103431502...\n",
      "Processing Ego Network: 103865085...\n",
      "Processing Ego Network: 103991905...\n",
      "Processing Ego Network: 104324908...\n",
      "Processing Ego Network: 104615636...\n",
      "Processing Ego Network: 1046661...\n",
      "Processing Ego Network: 104991493...\n",
      "Processing Ego Network: 105150583...\n",
      "Processing Ego Network: 105398724...\n",
      "Processing Ego Network: 105918870...\n",
      "--- Graph Built ---\n",
      "Total Nodes: 10160\n",
      "Total Edges: 53548\n",
      "Removing isolated nodes...\n",
      "Final Node Count: 10160\n",
      "--- Graph saved to ./twitter_graph.gpickle ---\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# CONFIGURATION\n",
    "DATA_DIR = 'Data/twitter' \n",
    "OUTPUT_GRAPH_PATH = 'models/twitter_graph.gpickle'\n",
    "MAX_NODES = 10000 # Limit graph size for laptop performance\n",
    "\n",
    "def build_twitter_graph(data_dir):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Get all \"Ego\" IDs (the filenames act as IDs)\n",
    "    # We look for .edges files to identify the ego networks\n",
    "    files = [f for f in os.listdir(data_dir) if f.endswith('.edges')]\n",
    "    ego_ids = [f.split('.')[0] for f in files]\n",
    "    \n",
    "    print(f\"--- Found {len(ego_ids)} Ego Networks ---\")\n",
    "    \n",
    "    node_count = 0\n",
    "    \n",
    "    for ego_id in ego_ids:\n",
    "        if node_count >= MAX_NODES:\n",
    "            break\n",
    "            \n",
    "        print(f\"Processing Ego Network: {ego_id}...\")\n",
    "        \n",
    "        # 1. Add User-User Edges (The \"Follow\" Graph)\n",
    "        edge_file = os.path.join(data_dir, f\"{ego_id}.edges\")\n",
    "        if os.path.exists(edge_file):\n",
    "            with open(edge_file, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    u, v = line.strip().split()\n",
    "                    G.add_node(u, type='user')\n",
    "                    G.add_node(v, type='user')\n",
    "                    G.add_edge(u, v, relation='follows')\n",
    "        \n",
    "        # 2. Add User-Feature Edges (The \"Interest\" Graph)\n",
    "        # .feat file contains binary vectors (0 0 1 0 1...)\n",
    "        # .featnames file contains what those 1s mean (e.g., \"234 school:Stanford\")\n",
    "        \n",
    "        feat_path = os.path.join(data_dir, f\"{ego_id}.feat\")\n",
    "        feat_names_path = os.path.join(data_dir, f\"{ego_id}.featnames\")\n",
    "        \n",
    "        if os.path.exists(feat_path) and os.path.exists(feat_names_path):\n",
    "            # Load feature definitions\n",
    "            # Map index 234 -> \"school:Stanford\"\n",
    "            feature_map = {} \n",
    "            with open(feat_names_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split(' ')\n",
    "                    feat_id = parts[0]\n",
    "                    feat_name = \" \".join(parts[1:]) # e.g., \"school;stanford\"\n",
    "                    feature_map[int(feat_id)] = feat_name\n",
    "\n",
    "            # Load user features\n",
    "            with open(feat_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split(' ')\n",
    "                    user_id = parts[0]\n",
    "                    features = parts[1:]\n",
    "                    \n",
    "                    # If this user is in our graph, link them to their features\n",
    "                    if G.has_node(user_id):\n",
    "                        for idx, val in enumerate(features):\n",
    "                            if val == '1' and idx in feature_map:\n",
    "                                feat_node_name = f\"Feat: {feature_map[idx]}\"\n",
    "                                # Add the Feature Node\n",
    "                                G.add_node(feat_node_name, type='feature')\n",
    "                                # Link User -> Feature\n",
    "                                G.add_edge(user_id, feat_node_name, relation='has_interest')\n",
    "\n",
    "        node_count = G.number_of_nodes()\n",
    "\n",
    "    print(f\"--- Graph Built ---\")\n",
    "    print(f\"Total Nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"Total Edges: {G.number_of_edges()}\")\n",
    "    \n",
    "    # Filter: Remove isolated nodes to clean the graph\n",
    "    print(\"Removing isolated nodes...\")\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "    print(f\"Final Node Count: {G.number_of_nodes()}\")\n",
    "    \n",
    "    return G\n",
    "\n",
    "def save_graph(G, output_path):\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(G, f)\n",
    "    print(f\"--- Graph saved to {output_path} ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        print(f\"Error: Directory {DATA_DIR} not found. Please extract twitter.tar.gz there.\")\n",
    "    else:\n",
    "        twitter_graph = build_twitter_graph(DATA_DIR)\n",
    "        save_graph(twitter_graph, OUTPUT_GRAPH_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
